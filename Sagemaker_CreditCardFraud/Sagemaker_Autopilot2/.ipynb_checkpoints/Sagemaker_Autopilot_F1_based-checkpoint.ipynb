{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Autopilot Candidate Definition Notebook\n",
    "The AutoML job **ccf-F1-score** generated this notebook automatically.\n",
    "You can modify the candidate definitions and run the SageMaker Autopilot workflow using this notebook.\n",
    "\n",
    "The target column is the **Class** column, which is one of the dataset's **31** columns. This is being handled as a problem with **BinaryClassification**. In addition, the dataset has **2** classes.\n",
    "This notebook will create a binary classification model that **maximises** the trained models' \"**F1**\" quality metric (see https://en.wikipedia.org/wiki/Binary_classification).\n",
    "For binary classification with a positive and negative class, the \"**F1**\" metric is used. It combines precision and recall and is advised in situations where there are more negative than positive examples.\n",
    "\n",
    "The input dataset has been randomly divided into two parts for **training** and **validation** as part of the AutoML job. You can examine and alter the data transformation strategies suggested by Amazon SageMaker Autopilot using this notebook. The data transformation models can be interactively trained and used to transform the data. Finally, by jointly optimising the data transformations and machine learning algorithms, you may run a multiple algorithm hyperparameter optimisation (multi-algo HPO) project to help you find the optimum model for your dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Setup\n",
    "\n",
    "Before you launch the SageMaker Autopilot jobs, we'll setup the environment for Amazon SageMaker\n",
    "- Check environment & dependencies.\n",
    "- Create a few helper objects/function to organize input/output data and SageMaker sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimal Environment Requirements**\n",
    "\n",
    "- Jupyter: Tested on `JupyterLab 1.0.6`, `jupyter_core 4.5.0` and `IPython 6.4.0`\n",
    "- Kernel: `conda_python3`\n",
    "- Dependencies required\n",
    "  - `sagemaker-python-sdk>=2.40.0`\n",
    "    - Use `!pip install sagemaker==2.40.0` to download this dependency.\n",
    "    - Kernel may need to be restarted after download.\n",
    "- Expected Execution Role/permission\n",
    "  - S3 access to the bucket that stores the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Generated Modules\n",
    "Download the generated data transformation modules and an SageMaker Autopilot helper module used by this notebook.\n",
    "Those artifacts will be downloaded to **ccf-F1-score-artifacts** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ccf-F1-score-artifacts\n",
    "!aws s3 sync s3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score/sagemaker-automl-candidates/ccf-F1-score-pr-1-9fd7c14660d9409893495022065874b394e9a0aeb5644/generated_module ccf-F1-score-artifacts/generated_module --only-show-errors\n",
    "!aws s3 sync s3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score/sagemaker-automl-candidates/ccf-F1-score-pr-1-9fd7c14660d9409893495022065874b394e9a0aeb5644/notebooks/sagemaker_automl ccf-F1-score-artifacts/sagemaker_automl --only-show-errors\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"ccf-F1-score-artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration\n",
    "\n",
    "The following configuration has been derived from the SageMaker Autopilot job. These items configure where this notebook will\n",
    "look for generated candidates, and where input and output data is stored on Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This notebook is initialized to use the following configuration: \n",
       "        <table>\n",
       "        <tr><th colspan=2>Name</th><th>Value</th></tr>\n",
       "        <tr><th>General</th><th>Role</th><td>arn:aws:iam::057057355214:role/service-role/AmazonSageMaker-ExecutionRole-20211118T193999</td></tr>\n",
       "        <tr><th rowspan=2>Base AutoML Job</th><th>Job Name</th><td>ccf-F1-score</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score</td></tr>\n",
       "        <tr><th rowspan=5>Interactive Job</th><th>Job Name</th><td>ccf-F1-sco-notebook-run-03-01-19-34</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score/ccf-F1-sco-notebook-run-03-01-19-34</td></tr>\n",
       "        <tr><th>Data Processing Trained Model Directory</th><td>s3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score/ccf-F1-sco-notebook-run-03-01-19-34/data-processor-models</td></tr>\n",
       "        <tr><th>Data Processing Transformed Output</th><td>s3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score/ccf-F1-sco-notebook-run-03-01-19-34/transformed-data</td></tr>\n",
       "        <tr><th>Algo Tuning Model Output Directory</th><td>s3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score/ccf-F1-sco-notebook-run-03-01-19-34/multi-algo-tuning</td></tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker_automl import uid, AutoMLLocalRunConfig\n",
    "\n",
    "# Where the preprocessed data from the existing AutoML job is stored\n",
    "BASE_AUTOML_JOB_NAME = 'ccf-F1-score'\n",
    "BASE_AUTOML_JOB_CONFIG = {\n",
    "    'automl_job_name': BASE_AUTOML_JOB_NAME,\n",
    "    'automl_output_s3_base_path': 's3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score',\n",
    "    'data_transformer_image_repo_version': '2.4-1-cpu-py3',\n",
    "    'algo_image_repo_versions': {'xgboost': '1.2-2-cpu-py3', 'linear-learner': 'latest', 'mlp': 'training-cpu'},\n",
    "    'algo_inference_image_repo_versions': {'xgboost': '1.2-2-cpu-py3', 'linear-learner': 'latest', 'mlp': 'inference-cpu'}\n",
    "}\n",
    "\n",
    "# Path conventions of the output data storage path from the local AutoML job run of this notebook\n",
    "LOCAL_AUTOML_JOB_NAME = 'ccf-F1-sco-notebook-run-{}'.format(uid())\n",
    "LOCAL_AUTOML_JOB_CONFIG = {\n",
    "    'local_automl_job_name': LOCAL_AUTOML_JOB_NAME,\n",
    "    'local_automl_job_output_s3_base_path': 's3://sagemaker-studio-057057355214-bh401jmpsm9/ccf-F1-score/{}'.format(LOCAL_AUTOML_JOB_NAME),\n",
    "    'data_processing_model_dir': 'data-processor-models',\n",
    "    'data_processing_transformed_output_dir': 'transformed-data',\n",
    "    'multi_algo_tuning_output_dir': 'multi-algo-tuning'\n",
    "}\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG = AutoMLLocalRunConfig(\n",
    "    role='arn:aws:iam::057057355214:role/service-role/AmazonSageMaker-ExecutionRole-20211118T193999',\n",
    "    base_automl_job_config=BASE_AUTOML_JOB_CONFIG,\n",
    "    local_automl_job_config=LOCAL_AUTOML_JOB_CONFIG,\n",
    "    security_config={'EnableInterContainerTrafficEncryption': False, 'VpcConfig': {}})\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Pipelines\n",
    "\n",
    "The `AutoMLLocalRunner` keeps track of selected candidates and automates many of the steps needed to execute feature engineering and tuning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_automl import AutoMLInteractiveRunner, AutoMLLocalCandidate\n",
    "\n",
    "automl_interactive_runner = AutoMLInteractiveRunner(AUTOML_LOCAL_RUN_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Candidates\n",
    "\n",
    "The SageMaker Autopilot Job has analyzed the dataset and has generated **7** machine learning\n",
    "pipeline(s) that use **3** algorithm(s). Each pipeline contains a set of feature transformers and an\n",
    "algorithm.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. The resource configuration: instance type & count\n",
    "1. Select candidate pipeline definitions by cells\n",
    "1. The linked data transformation script can be reviewed and updated. Please refer to the [README.md](./ccf-F1-score-artifacts/generated_module/README.md) for detailed customization instructions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp0-xgboost](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp0.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:19:35,753 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:35,829 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:35,834 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:35,856 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:35,858 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:35,876 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp0\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp1-xgboost](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp1.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:19:40,616 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:40,631 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:40,634 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:40,662 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:40,664 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:40,719 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp1\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp2-linear-learner](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp2.py)**: This data transformation strategy first transforms 'numeric' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [QuantileExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:19:43,975 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:43,997 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:44,001 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:44,002 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "2021-12-03 01:19:44,024 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:44,026 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:44,027 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "2021-12-03 01:19:44,064 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp2\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp3-xgboost](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp3.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:19:45,251 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:45,281 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:45,283 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:45,370 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:45,372 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:45,391 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp3\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp4-xgboost](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp4.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:19:46,267 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:46,290 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:46,292 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:46,312 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:46,319 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:46,347 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp4\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp5-xgboost](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp5.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:19:47,201 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:47,222 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:47,224 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:47,244 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:47,246 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:47,266 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp5\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp6-mlp](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp6.py)**: This data transformation strategy transforms 'numeric' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *mlp* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:19:48,205 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:48,229 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:48,231 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:48,232 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: training-cpu.\n",
      "2021-12-03 01:19:48,254 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:19:48,256 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-12-03 01:19:48,257 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: inference-cpu.\n",
      "2021-12-03 01:19:48,378 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp6\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"mlp\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"candidate_specific_static_hyperparameters\": {\n",
    "            \"num_categorical_features\": '0',\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Candidates\n",
    "\n",
    "You have selected the following candidates (please run the cell below and click on the feature transformer links for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <table>\n",
       "            <tr><th>Candidate Name</th><th>Algorithm</th><th>Feature Transformer</th></tr>\n",
       "            <tr><th>dpp0-xgboost</th><td>xgboost</td><td><a href='ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp0.py'>dpp0.py</a></td></tr>\n",
       "<tr><th>dpp1-xgboost</th><td>xgboost</td><td><a href='ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp1.py'>dpp1.py</a></td></tr>\n",
       "<tr><th>dpp2-linear-learner</th><td>linear-learner</td><td><a href='ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp2.py'>dpp2.py</a></td></tr>\n",
       "<tr><th>dpp3-xgboost</th><td>xgboost</td><td><a href='ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp3.py'>dpp3.py</a></td></tr>\n",
       "<tr><th>dpp4-xgboost</th><td>xgboost</td><td><a href='ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp4.py'>dpp4.py</a></td></tr>\n",
       "<tr><th>dpp5-xgboost</th><td>xgboost</td><td><a href='ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp5.py'>dpp5.py</a></td></tr>\n",
       "<tr><th>dpp6-mlp</th><td>mlp</td><td><a href='ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp6.py'>dpp6.py</a></td></tr>\n",
       "            </table>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl_interactive_runner.display_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature engineering pipeline consists of two SageMaker jobs:\n",
    "\n",
    "1. Generated trainable data transformer Python modules like [dpp0.py](ccf-F1-score-artifacts/generated_module/candidate_data_processors/dpp0.py), which has been downloaded to the local file system\n",
    "2. A **training** job to train the data transformers\n",
    "3. A **batch transform** job to apply the trained transformation to the dataset to generate the algorithm compatible data\n",
    "\n",
    "The transformers and its training pipeline are built using open sourced **[sagemaker-scikit-learn-container][]** and **[sagemaker-scikit-learn-extension][]**.\n",
    "\n",
    "[sagemaker-scikit-learn-container]: https://github.com/aws/sagemaker-scikit-learn-container\n",
    "[sagemaker-scikit-learn-extension]: https://github.com/aws/sagemaker-scikit-learn-extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Candidate Pipelines\n",
    "\n",
    "Each candidate pipeline consists of two steps, feature transformation and algorithm training.\n",
    "For efficiency first execute the feature transformation step which will generate a featurized dataset on S3\n",
    "for each pipeline.\n",
    "\n",
    "After each featurized dataset is prepared, execute a multi-algorithm tuning job that will run tuning jobs\n",
    "in parallel for each pipeline. This tuning job will execute training jobs to find the best set of\n",
    "hyper-parameters for each pipeline, as well as finding the overall best performing pipeline.\n",
    "\n",
    "### Run Data Transformation Steps\n",
    "\n",
    "Now you are ready to start execution all data transformation steps.  The cell below may take some time to finish,\n",
    "feel free to go grab a cup of coffee. To expedite the process you can set the number of `parallel_jobs` to be up to 10.\n",
    "Please check the account limits to increase the limits before increasing the number of jobs to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 01:25:10,859 INFO root: [Worker_0:dpp0-xgboost]Executing step: train_data_transformer\n",
      "2021-12-03 01:25:10,861 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 01:25:10,881 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:25:11,046 INFO sagemaker: Creating training-job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp0-train-03-01-25-09\n",
      "\n",
      "2021-12-03 01:25:11 Starting - Starting the training job2021-12-03 01:25:12,863 INFO root: [Worker_1:dpp1-xgboost]Executing step: train_data_transformer\n",
      "2021-12-03 01:25:12,864 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 01:25:12,890 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:25:13,022 INFO sagemaker: Creating training-job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp1-train-03-01-25-09\n",
      "\n",
      "2021-12-03 01:25:13 Starting - Starting the training job\n",
      "2021-12-03 01:25:14 Starting - Launching requested ML instances\n",
      "2021-12-03 01:25:18 Starting - Launching requested ML instances......................\n",
      "2021-12-03 01:26:13 Starting - Preparing the instances for training....\n",
      "2021-12-03 01:26:25 Starting - Preparing the instances for training...................................\n",
      "2021-12-03 01:27:55 Downloading - Downloading input data\n",
      "2021-12-03 01:27:59 Downloading - Downloading input data.....\n",
      "2021-12-03 01:28:16 Training - Downloading the training image....\n",
      "2021-12-03 01:28:25 Training - Downloading the training image\n",
      "2021-12-03 01:28:31 Training - Training image download completed. Training in progress.....\n",
      "2021-12-03 01:28:40 Training - Training image download completed. Training in progress.........\n",
      "2021-12-03 01:29:03 Uploading - Uploading generated training model\n",
      "2021-12-03 01:29:07 Uploading - Uploading generated training model\n",
      "2021-12-03 01:29:10 Completed - Training job completed\n",
      "2021-12-03 01:29:13,611 INFO root: [Worker_0:dpp0-xgboost]Executing step: create_transformer_model\n",
      "2021-12-03 01:29:13,639 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-12-03-01-29-13-612\n",
      ".2021-12-03 01:29:15,030 INFO root: [Worker_0:dpp0-xgboost]Executing step: perform_data_transform\n",
      "2021-12-03 01:29:15,033 INFO sagemaker: Creating transform job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp0-transform-03-01-25-09\n",
      ".\n",
      "2021-12-03 01:29:14 Completed - Training job completed\n",
      ".2021-12-03 01:29:22,580 INFO root: [Worker_1:dpp1-xgboost]Executing step: create_transformer_model\n",
      "2021-12-03 01:29:22,601 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-12-03-01-29-22-581\n",
      ".2021-12-03 01:29:26,017 INFO root: [Worker_1:dpp1-xgboost]Executing step: perform_data_transform\n",
      "2021-12-03 01:29:26,018 INFO sagemaker: Creating transform job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp1-transform-03-01-25-09\n",
      ".............................................................................................................................!\n",
      "2021-12-03 01:34:41,752 INFO root: [Worker_0:dpp2-linear-learner]Executing step: train_data_transformer\n",
      "2021-12-03 01:34:41,752 INFO root: Successfully fit data transformer for dpp0-xgboost\n",
      "2021-12-03 01:34:41,755 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 01:34:41,775 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:34:41,918 INFO sagemaker: Creating training-job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp2-train-03-01-25-09\n",
      "\n",
      "2021-12-03 01:34:42 Starting - Starting the training job!\n",
      "2021-12-03 01:34:42,722 INFO root: [Worker_1:dpp3-xgboost]Executing step: train_data_transformer\n",
      "2021-12-03 01:34:42,722 INFO root: Successfully fit data transformer for dpp1-xgboost\n",
      "2021-12-03 01:34:42,723 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 01:34:42,771 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:34:42,895 INFO sagemaker: Creating training-job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp3-train-03-01-25-09\n",
      "\n",
      "2021-12-03 01:34:45 Starting - Starting the training job\n",
      "2021-12-03 01:34:44 Starting - Launching requested ML instances\n",
      "2021-12-03 01:34:49 Starting - Launching requested ML instances.......................\n",
      "2021-12-03 01:35:50 Starting - Preparing the instances for training..\n",
      "2021-12-03 01:35:52 Starting - Preparing the instances for training..................................\n",
      "2021-12-03 01:37:25 Downloading - Downloading input data\n",
      "2021-12-03 01:37:25 Downloading - Downloading input data.......\n",
      "2021-12-03 01:37:47 Training - Downloading the training image\n",
      "2021-12-03 01:37:51 Training - Downloading the training image.....\n",
      "2021-12-03 01:38:06 Training - Training image download completed. Training in progress.\n",
      "2021-12-03 01:38:06 Training - Training image download completed. Training in progress...............\n",
      "2021-12-03 01:38:42 Uploading - Uploading generated training model.\n",
      "2021-12-03 01:38:50 Completed - Training job completed\n",
      "2021-12-03 01:38:52,283 INFO root: [Worker_1:dpp3-xgboost]Executing step: create_transformer_model\n",
      "2021-12-03 01:38:52,314 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-12-03-01-38-52-284\n",
      "2021-12-03 01:38:52,770 INFO root: [Worker_1:dpp3-xgboost]Executing step: perform_data_transform\n",
      "2021-12-03 01:38:52,773 INFO sagemaker: Creating transform job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp3-transform-03-01-25-09\n",
      "...\n",
      "2021-12-03 01:38:58 Uploading - Uploading generated training model...\n",
      "2021-12-03 01:39:05 Completed - Training job completed\n",
      "2021-12-03 01:39:08,656 INFO root: [Worker_0:dpp2-linear-learner]Executing step: create_transformer_model\n",
      "2021-12-03 01:39:08,680 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-12-03-01-39-08-657\n",
      "2021-12-03 01:39:09,073 INFO root: [Worker_0:dpp2-linear-learner]Executing step: perform_data_transform\n",
      "2021-12-03 01:39:09,074 INFO sagemaker: Creating transform job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp2-transform-03-01-25-09\n",
      "...............................................................................................................................!\n",
      "2021-12-03 01:44:29,532 INFO root: Successfully fit data transformer for dpp3-xgboost\n",
      "..2021-12-03 01:44:39,534 INFO root: [Worker_1:dpp4-xgboost]Executing step: train_data_transformer\n",
      "2021-12-03 01:44:39,536 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 01:44:39,572 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:44:39,718 INFO sagemaker: Creating training-job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp4-train-03-01-25-09\n",
      "\n",
      "2021-12-03 01:44:39 Starting - Starting the training job.\n",
      "2021-12-03 01:44:42 Starting - Launching requested ML instances!\n",
      "2021-12-03 01:44:45,861 INFO root: Successfully fit data transformer for dpp2-linear-learner\n",
      "2021-12-03 01:44:46,861 INFO root: [Worker_0:dpp5-xgboost]Executing step: train_data_transformer\n",
      "2021-12-03 01:44:46,862 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 01:44:46,888 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:44:47,014 INFO sagemaker: Creating training-job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp5-train-03-01-25-09\n",
      "\n",
      "2021-12-03 01:44:47 Starting - Starting the training job...\n",
      "2021-12-03 01:44:56 Starting - Launching requested ML instances......................\n",
      "2021-12-03 01:45:50 Starting - Preparing the instances for training..\n",
      "2021-12-03 01:45:57 Starting - Preparing the instances for training..........................\n",
      "2021-12-03 01:47:10 Downloading - Downloading input data........\n",
      "2021-12-03 01:47:29 Downloading - Downloading input data\n",
      "2021-12-03 01:47:32 Training - Downloading the training image........\n",
      "2021-12-03 01:47:54 Training - Downloading the training image.....\n",
      "2021-12-03 01:48:09 Training - Training image download completed. Training in progress.....\n",
      "2021-12-03 01:48:22 Training - Training image download completed. Training in progress...........\n",
      "2021-12-03 01:48:51 Uploading - Uploading generated training model\n",
      "2021-12-03 01:48:53 Uploading - Uploading generated training model\n",
      "2021-12-03 01:48:58 Completed - Training job completed\n",
      "2021-12-03 01:48:59,592 INFO root: [Worker_0:dpp5-xgboost]Executing step: create_transformer_model\n",
      "2021-12-03 01:48:59,616 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-12-03-01-48-59-594\n",
      "2021-12-03 01:49:01,023 INFO root: [Worker_0:dpp5-xgboost]Executing step: perform_data_transform\n",
      "2021-12-03 01:49:01,026 INFO sagemaker: Creating transform job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp5-transform-03-01-25-09\n",
      ".\n",
      "2021-12-03 01:49:00 Completed - Training job completed\n",
      ".2021-12-03 01:49:11,330 INFO root: [Worker_1:dpp4-xgboost]Executing step: create_transformer_model\n",
      ".2021-12-03 01:49:11,382 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-12-03-01-49-11-331\n",
      "..2021-12-03 01:49:21,813 INFO root: [Worker_1:dpp4-xgboost]Executing step: perform_data_transform\n",
      "2021-12-03 01:49:21,814 INFO sagemaker: Creating transform job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp4-transform-03-01-25-09\n",
      ".......................................................................................................................!\n",
      "2021-12-03 01:54:22,742 INFO root: [Worker_0:dpp6-mlp]Executing step: train_data_transformer\n",
      "2021-12-03 01:54:22,742 INFO root: Successfully fit data transformer for dpp5-xgboost\n",
      "2021-12-03 01:54:22,743 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 01:54:22,831 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 01:54:22,951 INFO sagemaker: Creating training-job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp6-train-03-01-25-09\n",
      "\n",
      "2021-12-03 01:54:23 Starting - Starting the training job.\n",
      "2021-12-03 01:54:26 Starting - Launching requested ML instances..............!\n",
      "2021-12-03 01:55:03,825 INFO root: Successfully fit data transformer for dpp4-xgboost\n",
      "......\n",
      "2021-12-03 01:55:37 Starting - Preparing the instances for training.....................\n",
      "2021-12-03 01:57:28 Downloading - Downloading input data..\n",
      "2021-12-03 01:57:39 Training - Downloading the training image...\n",
      "2021-12-03 01:57:59 Training - Training image download completed. Training in progress.......\n",
      "2021-12-03 01:58:36 Uploading - Uploading generated training model\n",
      "2021-12-03 01:58:44 Completed - Training job completed\n",
      "2021-12-03 01:58:44,589 INFO root: [Worker_0:dpp6-mlp]Executing step: create_transformer_model\n",
      "2021-12-03 01:58:44,628 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-12-03-01-58-44-591\n",
      "2021-12-03 01:58:45,019 INFO root: [Worker_0:dpp6-mlp]Executing step: perform_data_transform\n",
      "2021-12-03 01:58:45,027 INFO sagemaker: Creating transform job with name: ccf-F1-sco-notebook-run-03-01-19-34-dpp6-transform-03-01-25-09\n",
      "...................................................................!\n",
      "2021-12-03 02:04:21,851 INFO root: Successfully fit data transformer for dpp6-mlp\n",
      "2021-12-03 02:04:21,852 INFO root: Successfully fit 7 data transformers\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.fit_data_transformers(parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Algorithm Hyperparameter Tuning\n",
    "\n",
    "Now that the algorithm compatible transformed datasets are ready, you can start the multi-algorithm model tuning job\n",
    "to find the best predictive model. The following algorithm training job configuration for each\n",
    "algorithm is auto-generated by the AutoML Job as part of the recommendation.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Hyperparameter ranges\n",
    "2. Objective metrics\n",
    "3. Recommended static algorithm hyperparameters.\n",
    "\n",
    "Please refers to [Xgboost tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) and [Linear learner tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html) for detailed explanations of the parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML recommendation job has recommended the following hyperparameters, objectives and accuracy metrics for\n",
    "the algorithm and problem type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_OBJECTIVE_METRICS = {\n",
    "    'xgboost': 'validation:f1_binary',\n",
    "    'linear-learner': 'validation:binary_f_beta',\n",
    "    'mlp': 'validation:binary_f_beta',\n",
    "}\n",
    "\n",
    "STATIC_HYPERPARAMETERS = {\n",
    "    'xgboost': {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'accuracy,f1_binary,auc',\n",
    "        'scale_pos_weight': 577.8760162601626,\n",
    "        'save_model_on_termination': 'true',\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'loss': 'logistic',\n",
    "        'mini_batch_size': 800,\n",
    "        'binary_classifier_model_selection_criteria': 'loss_function',\n",
    "        'num_models': 1,\n",
    "        'positive_example_weight_mult': 577.8760162601626,\n",
    "    },\n",
    "    'mlp': {\n",
    "        'problem_type': 'binary_classification',\n",
    "        'positive_example_weight_mult': 577.8760162601626,\n",
    "        'ml_application': 'mlp',\n",
    "        'use_batchnorm': 'true',\n",
    "        'activation': 'relu',\n",
    "        'warmup_epochs': 10,\n",
    "        'reporting_metrics': 'accuracy,binary_f_1,roc_auc',\n",
    "        'eval_metric': 'binary_f_1',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tunable hyperparameters search ranges are recommended for the Multi-Algo tuning job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES = {\n",
    "    'xgboost': {\n",
    "        'num_round': IntegerParameter(64, 1024, scaling_type='Logarithmic'),\n",
    "        'max_depth': IntegerParameter(2, 8, scaling_type='Logarithmic'),\n",
    "        'eta': ContinuousParameter(1e-3, 1.0, scaling_type='Logarithmic'),\n",
    "        'gamma': ContinuousParameter(1e-6, 64.0, scaling_type='Logarithmic'),\n",
    "        'min_child_weight': ContinuousParameter(1e-6, 32.0, scaling_type='Logarithmic'),\n",
    "        'subsample': ContinuousParameter(0.5, 1.0, scaling_type='Linear'),\n",
    "        'colsample_bytree': ContinuousParameter(0.3, 1.0, scaling_type='Linear'),\n",
    "        'lambda': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "        'alpha': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'wd': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'l1': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'learning_rate': ContinuousParameter(1e-5, 1.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'mlp': {\n",
    "        'mini_batch_size': IntegerParameter(128, 512, scaling_type='Linear'),\n",
    "        'learning_rate': ContinuousParameter(1e-6, 1e-2, scaling_type='Logarithmic'),\n",
    "        'weight_decay': ContinuousParameter(1e-12, 1e-2, scaling_type='Logarithmic'),\n",
    "        'dropout_prob': ContinuousParameter(0.25, 0.5, scaling_type='Linear'),\n",
    "        'embedding_size_factor': ContinuousParameter(0.65, 0.95, scaling_type='Linear'),\n",
    "        'network_type': CategoricalParameter(['feedforward', 'widedeep']),\n",
    "        'layers': CategoricalParameter(['256', '50, 25', '100, 50', '200, 100', '256, 128', '300, 150', '200, 100, 50']),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Multi-Algorithm Tuner Input\n",
    "\n",
    "To use the multi-algorithm HPO tuner, prepare some inputs and parameters. Prepare a dictionary whose key is the name of the trained pipeline candidates and the values are respectively:\n",
    "\n",
    "1. Estimators for the recommended algorithm\n",
    "2. Hyperparameters search ranges\n",
    "3. Objective metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_parameters = automl_interactive_runner.prepare_multi_algo_parameters(\n",
    "    objective_metrics=ALGORITHM_OBJECTIVE_METRICS,\n",
    "    static_hyperparameters=STATIC_HYPERPARAMETERS,\n",
    "    hyperparameters_search_ranges=ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you prepare the inputs data to the multi-algo tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_inputs = automl_interactive_runner.prepare_multi_algo_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Multi-Algorithm Tuner\n",
    "\n",
    "With the recommended Hyperparameter ranges and the transformed dataset, create a multi-algorithm model tuning job\n",
    "that coordinates hyper parameter optimizations across the different possible algorithms and feature processing strategies.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Tuner strategy: [Bayesian](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization), [Random Search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search)\n",
    "2. Objective type: `Minimize`, `Maximize`, see [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)\n",
    "3. Max Job size: the max number of training jobs HPO would be launching to run experiments. Note the default value is **250**\n",
    "    which is the default of the managed flow.\n",
    "4. Parallelism. Number of jobs that will be executed in parallel. Higher value will expedite the tuning process.\n",
    "    Please check the account limits to increase the limits before increasing the number of jobs to run in parallel\n",
    "5. Please use a different tuning job name if you re-run this cell after applied customizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "base_tuning_job_name = \"{}-tuning\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name)\n",
    "\n",
    "tuner = HyperparameterTuner.create(\n",
    "    base_tuning_job_name=base_tuning_job_name,\n",
    "    strategy='Bayesian',\n",
    "    objective_type='Maximize',\n",
    "    max_parallel_jobs=2,\n",
    "    max_jobs=250,\n",
    "    **multi_algo_tuning_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Multi-Algorithm Tuning\n",
    "\n",
    "Now you are ready to start running the **Multi-Algo Tuning** job. After the job is finished, store the tuning job name which you use to select models in the next section.\n",
    "The tuning process will take some time, please track the progress in the Amazon SageMaker Hyperparameter tuning jobs console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 02:06:09,330 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 02:06:09,350 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 02:06:09,352 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 02:06:09,373 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 02:06:09,374 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 02:06:09,394 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 02:06:09,396 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 02:06:09,415 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 02:06:09,417 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 02:06:09,437 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 02:06:09,439 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 02:06:09,459 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 02:06:09,461 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-12-03 02:06:09,482 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-12-03 02:06:09,488 INFO sagemaker: Creating hyperparameter tuning job with name: ccf-F1-sco-notebook--211203-0206\n",
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Run tuning\n",
    "tuner.fit(inputs=multi_algo_tuning_inputs, include_cls_metadata=None)\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "\n",
    "display(\n",
    "    Markdown(f\"Tuning Job {tuning_job_name} started, please track the progress from [here](https://{AUTOML_LOCAL_RUN_CONFIG.region}.console.aws.amazon.com/sagemaker/home?region={AUTOML_LOCAL_RUN_CONFIG.region}#/hyper-tuning-jobs/{tuning_job_name})\"))\n",
    "\n",
    "# Wait for tuning job to finish\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Deployment\n",
    "\n",
    "This section guides you through the model selection process. Afterward, you construct an inference pipeline\n",
    "on Amazon SageMaker to host the best candidate.\n",
    "\n",
    "Because you executed the feature transformation and algorithm training in two separate steps, you now need to manually\n",
    "link each trained model with the feature transformer that it is associated with. When running a regular Amazon\n",
    "SageMaker Autopilot job, this will automatically be done for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Job Result Overview\n",
    "\n",
    "The performance of each candidate pipeline can be viewed as a Pandas dataframe. For more interactive usage please\n",
    "refers to [model tuning monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-monitor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lambda</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>num_round</th>\n",
       "      <th>subsample</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>...</th>\n",
       "      <th>TrainingJobDefinitionName</th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>embedding_size_factor</th>\n",
       "      <th>layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mini_batch_size</th>\n",
       "      <th>network_type</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>l1</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.945699</td>\n",
       "      <td>0.319618</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.510349</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.359117</td>\n",
       "      <td>573.0</td>\n",
       "      <td>0.603489</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-220-6ea75adc</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.532783</td>\n",
       "      <td>0.439610</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.056962</td>\n",
       "      <td>795.0</td>\n",
       "      <td>0.912518</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-204-d8ecc56f</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.026534</td>\n",
       "      <td>0.730017</td>\n",
       "      <td>0.177250</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.616748</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-208-835ef8b4</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.026814</td>\n",
       "      <td>0.624249</td>\n",
       "      <td>0.265388</td>\n",
       "      <td>0.739151</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.600228</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.837048</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-236-7bc617b0</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.505097</td>\n",
       "      <td>0.278809</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.788247</td>\n",
       "      <td>775.0</td>\n",
       "      <td>0.917277</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-128-47f9a4db</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.609035</td>\n",
       "      <td>0.086090</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.078096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.591670</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-001-158129f8</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.457469</td>\n",
       "      <td>0.219402</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.778362</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.777983</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-190-d06d9b0d</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.563174</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.946195</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.914601</td>\n",
       "      <td>644.0</td>\n",
       "      <td>0.644743</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-127-62e8e126</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.021682</td>\n",
       "      <td>0.790943</td>\n",
       "      <td>0.219503</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.629311</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.035587</td>\n",
       "      <td>604.0</td>\n",
       "      <td>0.597469</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-114-6bc46622</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.668270</td>\n",
       "      <td>0.615661</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>1.204446</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.524313</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-178-31360477</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.738885</td>\n",
       "      <td>0.236320</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>1.633857</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.185043</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0.710823</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-042-4cb3100f</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.020579</td>\n",
       "      <td>0.590979</td>\n",
       "      <td>0.477992</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.873905</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.907235</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-227-f7cb37ad</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.392023</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.368816</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.136246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.542904</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.775798</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-188-9aec4fbf</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.633047</td>\n",
       "      <td>0.287340</td>\n",
       "      <td>0.068722</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.442361</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0.613804</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-230-59b02dee</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.813175</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.288958</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>716.0</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-166-41ea6b94</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.412687</td>\n",
       "      <td>0.245266</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.870391</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>621.0</td>\n",
       "      <td>0.516622</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-146-bd4eeaab</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.581815</td>\n",
       "      <td>0.507022</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.203142</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.894026</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-183-04c079c1</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.581821</td>\n",
       "      <td>0.152848</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.037869</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.483847</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.717175</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-186-f898e370</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.493746</td>\n",
       "      <td>0.187342</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>1.794927</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>481.0</td>\n",
       "      <td>0.616666</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-126-7afa67ab</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.821625</td>\n",
       "      <td>0.520482</td>\n",
       "      <td>0.120832</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.726165</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.705195</td>\n",
       "      <td>ccf-F1-sco-notebook--211203-0206-111-105995ac</td>\n",
       "      <td>...</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha  colsample_bytree       eta     gamma    lambda  max_depth  \\\n",
       "30   0.000003          0.945699  0.319618  0.000005  0.510349        3.0   \n",
       "46   0.000158          0.532783  0.439610  0.000225  0.004294        5.0   \n",
       "42   0.026534          0.730017  0.177250  0.000002  2.000000        5.0   \n",
       "14   0.026814          0.624249  0.265388  0.739151  0.000104        5.0   \n",
       "122  0.000005          0.505097  0.278809  0.000017  0.000612        5.0   \n",
       "249  0.000121          0.609035  0.086090  0.000005  0.078096        4.0   \n",
       "60   0.020637          0.457469  0.219402  0.000001  0.000112        2.0   \n",
       "123  0.000012          0.563174  0.109192  0.000001  0.946195        8.0   \n",
       "136  0.021682          0.790943  0.219503  0.000019  1.629311        7.0   \n",
       "72   0.000427          0.668270  0.615661  0.000419  1.204446        3.0   \n",
       "208  0.001206          0.738885  0.236320  0.013931  1.633857        5.0   \n",
       "23   0.020579          0.590979  0.477992  0.000166  0.000213        4.0   \n",
       "62   0.392023          0.502762  0.368816  0.000105  0.136246        2.0   \n",
       "20   0.000002          0.633047  0.287340  0.068722  0.000005        5.0   \n",
       "84   0.000051          0.813175  0.120326  0.000004  0.288958        5.0   \n",
       "104  0.000184          0.412687  0.245266  0.000016  0.870391        6.0   \n",
       "67   0.000057          0.581815  0.507022  0.000116  0.008682        3.0   \n",
       "64   0.016897          0.581821  0.152848  0.000058  0.037869        3.0   \n",
       "124  0.000104          0.493746  0.187342  0.000110  1.794927        5.0   \n",
       "139  0.821625          0.520482  0.120832  0.000002  0.726165        7.0   \n",
       "\n",
       "     min_child_weight  num_round  subsample  \\\n",
       "30           0.359117      573.0   0.603489   \n",
       "46           9.056962      795.0   0.912518   \n",
       "42           0.000041      407.0   0.616748   \n",
       "14          13.600228     1024.0   0.837048   \n",
       "122          4.788247      775.0   0.917277   \n",
       "249          0.000004      455.0   0.591670   \n",
       "60           3.778362     1024.0   0.777983   \n",
       "123          3.914601      644.0   0.644743   \n",
       "136          0.035587      604.0   0.597469   \n",
       "72           0.000028      994.0   0.524313   \n",
       "208          0.185043      388.0   0.710823   \n",
       "23          14.873905      449.0   0.907235   \n",
       "62           0.542904     1024.0   0.775798   \n",
       "20           6.442361      262.0   0.613804   \n",
       "84           0.005098      716.0   0.975155   \n",
       "104          0.000013      621.0   0.516622   \n",
       "67          12.203142     1008.0   0.894026   \n",
       "64           1.483847     1024.0   0.717175   \n",
       "124          0.063920      481.0   0.616666   \n",
       "139          0.011090      689.0   0.705195   \n",
       "\n",
       "                                   TrainingJobName  ...  \\\n",
       "30   ccf-F1-sco-notebook--211203-0206-220-6ea75adc  ...   \n",
       "46   ccf-F1-sco-notebook--211203-0206-204-d8ecc56f  ...   \n",
       "42   ccf-F1-sco-notebook--211203-0206-208-835ef8b4  ...   \n",
       "14   ccf-F1-sco-notebook--211203-0206-236-7bc617b0  ...   \n",
       "122  ccf-F1-sco-notebook--211203-0206-128-47f9a4db  ...   \n",
       "249  ccf-F1-sco-notebook--211203-0206-001-158129f8  ...   \n",
       "60   ccf-F1-sco-notebook--211203-0206-190-d06d9b0d  ...   \n",
       "123  ccf-F1-sco-notebook--211203-0206-127-62e8e126  ...   \n",
       "136  ccf-F1-sco-notebook--211203-0206-114-6bc46622  ...   \n",
       "72   ccf-F1-sco-notebook--211203-0206-178-31360477  ...   \n",
       "208  ccf-F1-sco-notebook--211203-0206-042-4cb3100f  ...   \n",
       "23   ccf-F1-sco-notebook--211203-0206-227-f7cb37ad  ...   \n",
       "62   ccf-F1-sco-notebook--211203-0206-188-9aec4fbf  ...   \n",
       "20   ccf-F1-sco-notebook--211203-0206-230-59b02dee  ...   \n",
       "84   ccf-F1-sco-notebook--211203-0206-166-41ea6b94  ...   \n",
       "104  ccf-F1-sco-notebook--211203-0206-146-bd4eeaab  ...   \n",
       "67   ccf-F1-sco-notebook--211203-0206-183-04c079c1  ...   \n",
       "64   ccf-F1-sco-notebook--211203-0206-186-f898e370  ...   \n",
       "124  ccf-F1-sco-notebook--211203-0206-126-7afa67ab  ...   \n",
       "139  ccf-F1-sco-notebook--211203-0206-111-105995ac  ...   \n",
       "\n",
       "    TrainingJobDefinitionName  dropout_prob embedding_size_factor layers  \\\n",
       "30               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "46               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "42               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "14               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "122              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "249              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "60               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "123              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "136              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "72               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "208              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "23               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "62               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "20               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "84               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "104              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "67               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "64               dpp3-xgboost           NaN                   NaN    NaN   \n",
       "124              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "139              dpp3-xgboost           NaN                   NaN    NaN   \n",
       "\n",
       "     learning_rate mini_batch_size  network_type  weight_decay  l1  wd  \n",
       "30             NaN             NaN           NaN           NaN NaN NaN  \n",
       "46             NaN             NaN           NaN           NaN NaN NaN  \n",
       "42             NaN             NaN           NaN           NaN NaN NaN  \n",
       "14             NaN             NaN           NaN           NaN NaN NaN  \n",
       "122            NaN             NaN           NaN           NaN NaN NaN  \n",
       "249            NaN             NaN           NaN           NaN NaN NaN  \n",
       "60             NaN             NaN           NaN           NaN NaN NaN  \n",
       "123            NaN             NaN           NaN           NaN NaN NaN  \n",
       "136            NaN             NaN           NaN           NaN NaN NaN  \n",
       "72             NaN             NaN           NaN           NaN NaN NaN  \n",
       "208            NaN             NaN           NaN           NaN NaN NaN  \n",
       "23             NaN             NaN           NaN           NaN NaN NaN  \n",
       "62             NaN             NaN           NaN           NaN NaN NaN  \n",
       "20             NaN             NaN           NaN           NaN NaN NaN  \n",
       "84             NaN             NaN           NaN           NaN NaN NaN  \n",
       "104            NaN             NaN           NaN           NaN NaN NaN  \n",
       "67             NaN             NaN           NaN           NaN NaN NaN  \n",
       "64             NaN             NaN           NaN           NaN NaN NaN  \n",
       "124            NaN             NaN           NaN           NaN NaN NaN  \n",
       "139            NaN             NaN           NaN           NaN NaN NaN  \n",
       "\n",
       "[20 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "SAGEMAKER_SESSION = AUTOML_LOCAL_RUN_CONFIG.sagemaker_session\n",
    "SAGEMAKER_ROLE = AUTOML_LOCAL_RUN_CONFIG.role\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best training job can be selected as below:\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong>Tips: </strong>\n",
    "You could select alternative job by using the value from `TrainingJobName` column above and assign to `best_training_job` below\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Multi Algorithm HPO training job name is ccf-F1-sco-notebook--211203-0206-220-6ea75adc\n"
     ]
    }
   ],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "best_training_job = attached_tuner.best_training_job()\n",
    "\n",
    "print(\"Best Multi Algorithm HPO training job name is {}\".format(best_training_job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Best Training Job with Feature Pipelines\n",
    "\n",
    "Finally, deploy the best training job to Amazon SageMaker along with its companion feature engineering models.\n",
    "At the end of the section, you get an endpoint that's ready to serve online inference or start batch transform jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a [PipelineModel](https://sagemaker.readthedocs.io/en/stable/pipeline.html) that has multiple containers of the following:\n",
    "\n",
    "1. Data Transformation Container: a container built from the model we selected and trained during the data transformer sections\n",
    "2. Algorithm Container: a container built from the trained model we selected above from the best HPO training job.\n",
    "3. Inverse Label Transformer Container: a container that converts numerical intermediate prediction value back to non-numerical label value.\n",
    "\n",
    "Get both best data transformation model and algorithm model from best training job and create an pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 15:01:54,858 INFO root: Chosen Data Processing pipeline candidate name is dpp3-xgboost\n",
      "\n",
      "2021-12-03 01:39:32 Starting - Preparing the instances for training\n",
      "2021-12-03 01:39:32 Downloading - Downloading input data\n",
      "2021-12-03 01:39:32 Training - Training image download completed. Training in progress.\n",
      "2021-12-03 01:39:32 Uploading - Uploading generated training model\n",
      "2021-12-03 01:39:32 Completed - Training job completed\n",
      "\n",
      "2021-12-03 14:35:02 Starting - Preparing the instances for training\n",
      "2021-12-03 14:35:02 Downloading - Downloading input data\n",
      "2021-12-03 14:35:02 Training - Training image download completed. Training in progress.\n",
      "2021-12-03 14:35:02 Uploading - Uploading generated training model\n",
      "2021-12-03 14:35:02 Completed - Training job completed\n",
      "\n",
      "2021-12-03 01:39:32 Starting - Preparing the instances for training\n",
      "2021-12-03 01:39:32 Downloading - Downloading input data\n",
      "2021-12-03 01:39:32 Training - Training image download completed. Training in progress.\n",
      "2021-12-03 01:39:32 Uploading - Uploading generated training model\n",
      "2021-12-03 01:39:32 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import PipelineModel\n",
    "from sagemaker_automl import select_inference_output\n",
    "\n",
    "# Get a data transformation model from chosen candidate\n",
    "best_candidate = automl_interactive_runner.choose_candidate(df_tuning_job_analytics, best_training_job)\n",
    "best_data_transformer_model = best_candidate.get_data_transformer_model(role=SAGEMAKER_ROLE, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "# Our first data transformation container will always return recordio-protobuf format\n",
    "best_data_transformer_model.env[\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\"] = 'application/x-recordio-protobuf'\n",
    "# Add environment variable for sparse encoding\n",
    "if best_candidate.data_transformer_step.sparse_encoding:\n",
    "    best_data_transformer_model.env[\"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\"] = '1'\n",
    "\n",
    "# Get a algo model from chosen training job of the candidate\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "best_algo_model = algo_estimator.create_model(**best_candidate.algo_step.get_inference_container_config())\n",
    "\n",
    "# Final pipeline model is composed of data transformation models and algo model and an\n",
    "# inverse label transform model if we need to transform the intermediates back to non-numerical value\n",
    "model_containers = [best_data_transformer_model, best_algo_model]\n",
    "if best_candidate.transforms_label:\n",
    "    model_containers.append(best_candidate.get_data_transformer_model(\n",
    "        transform_mode=\"inverse-label-transform\",\n",
    "        role=SAGEMAKER_ROLE,\n",
    "        sagemaker_session=SAGEMAKER_SESSION))\n",
    "\n",
    "# This model can emit response ['predicted_label', 'probability', 'labels', 'probabilities']. To enable the model to emit one or more\n",
    "# of the response content, pass the keys to `output_key` keyword argument in the select_inference_output method.\n",
    "\n",
    "model_containers = select_inference_output(\"BinaryClassification\", model_containers, output_keys=['predicted_label'])\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=\"AutoML-{}\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name),\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    models=model_containers,\n",
    "    vpc_config=AUTOML_LOCAL_RUN_CONFIG.vpc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Best Pipeline\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. You can customize the initial instance count and instance type used to deploy this model.\n",
    "2. Endpoint name can be changed to avoid conflict with existing endpoints.\n",
    "\n",
    "</div>\n",
    "\n",
    "Finally, deploy the model to SageMaker to make it functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.deploy(initial_instance_count=1,\n",
    "                      instance_type='ml.t2.medium', # Changed from ml.m5.2xlarge to allow for endpoint creation in AWS free tier\n",
    "                      endpoint_name=pipeline_model.name,\n",
    "                      wait=True)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
